import pandas as pd
import json
from pathlib import Path
import os

# ==============================================================================
# âœ… å”¯ä¸€éœ€è¦æ‚¨ä¿®æ”¹çš„åœ°æ–¹ âœ…
# è¯·å°†ä¸‹é¢çš„è·¯å¾„æ›¿æ¢ä¸ºæ‚¨å®é™…çš„ Ray Tune å®éªŒç»“æœæ–‡ä»¶å¤¹è·¯å¾„ã€‚
# è·¯å¾„é€šå¸¸æ˜¯ ".../LKO_GridSearch_ray_Final/GridSearch_Delay_IMult_Seed"
EXPERIMENT_RESULTS_PATH = Path(
    "/root/autodl-tmp/python_koopman_project/src/DRKO/models/LKO_GridSearch_ray_Final_motion8_update/GridSearch_Delay_IMult_Seed")


# ==============================================================================


def analyze_ray_results(experiment_path: Path):
    """
    åŠ è½½ Ray Tune å®éªŒæ–‡ä»¶å¤¹ï¼Œè¯»å–æ‰€æœ‰æœ‰æ•ˆè¯•éªŒçš„ç»“æœï¼Œ
    å¹¶ç”Ÿæˆä¸€ä¸ªæŒ‰ RMSE é™åºæ’åˆ—çš„ DataFrameã€‚

    Args:
        experiment_path (Path): æŒ‡å‘ Ray Tune å®éªŒä¸»ç›®å½•çš„è·¯å¾„ã€‚
    """
    print(f"--- æ­£åœ¨ä»ä»¥ä¸‹è·¯å¾„åŠ è½½å®éªŒç»“æœ ---\n{experiment_path}\n")

    if not experiment_path.is_dir():
        print(f"âŒ é”™è¯¯: è·¯å¾„ä¸å­˜åœ¨æˆ–ä¸æ˜¯ä¸€ä¸ªæ–‡ä»¶å¤¹: {experiment_path}")
        return

    # ä½¿ç”¨ glob æŸ¥æ‰¾æ‰€æœ‰åŒ…å« params.json çš„è¯•éªŒæ–‡ä»¶å¤¹
    # è¿™æ˜¯å®šä½åˆ°æ¯ä¸€ä¸ªå…·ä½“è¯•éªŒçš„å¯é æ–¹æ³•
    all_param_files = list(experiment_path.glob("**/params.json"))

    if not all_param_files:
        print("âŒ é”™è¯¯: åœ¨æŒ‡å®šè·¯å¾„ä¸‹æœªæ‰¾åˆ°ä»»ä½•è¯•éªŒæ–‡ä»¶å¤¹ï¼ˆæ²¡æœ‰æ‰¾åˆ° params.json æ–‡ä»¶ï¼‰ã€‚è¯·æ£€æŸ¥è·¯å¾„æ˜¯å¦æ­£ç¡®ã€‚")
        return

    print(f"ğŸ” æ‰¾åˆ°äº† {len(all_param_files)} ä¸ªè¯•éªŒæ–‡ä»¶å¤¹ï¼Œæ­£åœ¨å¼€å§‹è§£æ...")

    all_valid_results = []
    skipped_count = 0

    for param_file_path in all_param_files:
        trial_path = param_file_path.parent
        result_file_path = trial_path / "result.json"

        # æ ¸å¿ƒæ£€æŸ¥ï¼šç¡®ä¿ result.json æ–‡ä»¶å­˜åœ¨ä¸”å†…å®¹ä¸ä¸ºç©º
        if not result_file_path.exists() or os.path.getsize(result_file_path) == 0:
            # print(f"  - è·³è¿‡: {trial_path.name} (result.json ä¸ºç©ºæˆ–ä¸å­˜åœ¨)")
            skipped_count += 1
            continue

        try:
            # result.json æ˜¯ä¸€ä¸ª JSON-lines æ–‡ä»¶ï¼Œæ¯è¡Œæ˜¯ä¸€ä¸ªJSONå¯¹è±¡
            # æˆ‘ä»¬åªéœ€è¦æœ€åä¸€è¡Œï¼Œå› ä¸ºå®ƒåŒ…å«äº†æœ€ç»ˆçš„æ€§èƒ½æŒ‡æ ‡
            with open(result_file_path, 'r', encoding='utf-8') as f:
                last_line = f.readlines()[-1]

            result_data = json.loads(last_line)

            # è¯»å–å¯¹åº”çš„è¶…å‚æ•°æ–‡ä»¶
            with open(param_file_path, 'r', encoding='utf-8') as f:
                param_data = json.load(f)

            # æå–æ‰€éœ€ä¿¡æ¯
            rmse = result_data.get("rmse")
            delay_step = param_data.get("delay_step")
            i_multiplier = param_data.get("i_multiplier")
            seed = param_data.get("seed")

            # ç¡®ä¿æ‰€æœ‰éœ€è¦çš„ä¿¡æ¯éƒ½æˆåŠŸæå–
            if all(v is not None for v in [rmse, delay_step, i_multiplier, seed]):
                all_valid_results.append({
                    "delay_step": delay_step,
                    "i_multiplier": i_multiplier,
                    "seed": seed,
                    "rmse": rmse,
                    "trial_path": str(trial_path)  # æ·»åŠ ç”¨æˆ·è¦æ±‚çš„è·¯å¾„ä¿¡æ¯
                })
            else:
                skipped_count += 1
                # print(f"  - è·³è¿‡: {trial_path.name} (æ•°æ®å­—æ®µä¸å®Œæ•´)")


        except (json.JSONDecodeError, IndexError) as e:
            # æ•è·è§£æé”™è¯¯æˆ–æ–‡ä»¶ä¸ºç©ºè¡Œçš„å¼‚å¸¸
            skipped_count += 1
            # print(f"  - è·³è¿‡: {trial_path.name} (æ–‡ä»¶æŸå: {e})")
            continue

    print(f"\n--- è§£æå®Œæˆ ---")
    print(f"âœ”ï¸ æˆåŠŸè§£æäº† {len(all_valid_results)} ä¸ªæœ‰æ•ˆè¯•éªŒç»“æœã€‚")
    print(f"â­ï¸ è·³è¿‡äº† {skipped_count} ä¸ªæ— æ•ˆæˆ–ç©ºçš„è¯•éªŒã€‚")

    if not all_valid_results:
        print("\nâŒ æœªèƒ½ä»ä»»ä½•è¯•éªŒä¸­æå–æœ‰æ•ˆç»“æœã€‚")
        return

    # åˆ›å»º DataFrame
    results_df = pd.DataFrame(all_valid_results)

    # æŒ‰ç…§ RMSE ä»é«˜åˆ°ä½æ’åº
    results_df.sort_values(by="rmse", ascending=False, inplace=True)

    # ç¾åŒ–å’Œæ‰“å°è¡¨æ ¼
    pd.set_option('display.max_rows', None)
    pd.set_option('display.max_columns', None)
    pd.set_option('display.width', 1200)  # å¢åŠ å®½åº¦ä»¥å®¹çº³è·¯å¾„
    pd.set_option('display.max_colwidth', None)  # æ˜¾ç¤ºå®Œæ•´è·¯å¾„

    print("\n\n--- é‡æ–°ç”Ÿæˆçš„æœ€ç»ˆç»“æœè¡¨ (æŒ‰ RMSE é™åºæ’åˆ—) ---")
    print(results_df.to_string(index=False))

    # ä¿å­˜åˆ°æ–°çš„CSVæ–‡ä»¶
    save_path = experiment_path.parent / "regenerated_results_table.csv"
    try:
        results_df.to_csv(save_path, index=False, encoding='utf-8')
        print(f"\n\nâœ… æœ€ç»ˆè¡¨æ ¼å·²æˆåŠŸä¿å­˜è‡³:\n{save_path}")
    except Exception as e:
        print(f"\n\nâŒ ä¿å­˜æ–‡ä»¶æ—¶å‡ºé”™: {e}")


if __name__ == '__main__':
    analyze_ray_results(EXPERIMENT_RESULTS_PATH)